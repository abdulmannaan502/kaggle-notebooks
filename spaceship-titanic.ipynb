{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":34377,"databundleVersionId":3220602,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.impute import SimpleImputer\n\n# 1. Load data\ntrain = pd.read_csv(\"/kaggle/input/spaceship-titanic/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/spaceship-titanic/test.csv\")\n\n# 2. Preprocess / feature engineering\ndef preprocess(df, is_train=True):\n    df = df.copy()\n\n    # Cabin â†’ Deck, Side\n    df[\"Deck\"] = df[\"Cabin\"].apply(lambda x: str(x).split(\"/\")[0] if pd.notnull(x) else \"Unknown\")\n    df[\"Side\"] = df[\"Cabin\"].apply(lambda x: str(x).split(\"/\")[-1] if pd.notnull(x) else \"Unknown\")\n\n    # Drop columns not used\n    drop_cols = [\"PassengerId\", \"Cabin\", \"Name\"]\n    if is_train:\n        y = df[\"Transported\"].astype(int)\n        drop_cols.append(\"Transported\")\n    else:\n        y = None\n\n    df = df.drop(columns=drop_cols)\n    return df, y\n\nX_train_raw, y_train = preprocess(train, is_train=True)\nX_test_raw, _ = preprocess(test, is_train=False)\n\n# Identify column types\ncategorical_cols = X_train_raw.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\nnumeric_cols = X_train_raw.select_dtypes(include=[\"number\"]).columns.tolist()\n\n# Imputation + encoding\npreprocessor = ColumnTransformer([\n    (\"cat\", Pipeline([\n        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n    ]), categorical_cols),\n\n    (\"num\", Pipeline([\n        (\"imputer\", SimpleImputer(strategy=\"median\"))\n    ]), numeric_cols)\n\n], remainder=\"passthrough\")\n\n# 3. Build a pipeline with RandomForest\nclf = Pipeline([\n    (\"pre\", preprocessor),\n    (\"rf\", RandomForestClassifier(n_estimators=200, random_state=42))\n])\n\n# 4. Validation split\nX_tr, X_val, y_tr, y_val = train_test_split(\n    X_train_raw, y_train, test_size=0.2, random_state=42\n)\n\nclf.fit(X_tr, y_tr)\nprint(\"Validation accuracy:\", clf.score(X_val, y_val))\n\n# 5. Train on all training data\nclf.fit(X_train_raw, y_train)\npred = clf.predict(X_test_raw)\n\n# 6. Submission file\nsubmission = pd.DataFrame({\n    \"PassengerId\": test[\"PassengerId\"],\n    \"Transported\": pred.astype(bool)\n})\n\nsubmission.to_csv(\"submission.csv\", index=False)\nprint(\"submission.csv saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T07:28:46.171836Z","iopub.execute_input":"2025-12-01T07:28:46.172201Z","iopub.status.idle":"2025-12-01T07:28:50.869987Z","shell.execute_reply.started":"2025-12-01T07:28:46.172170Z","shell.execute_reply":"2025-12-01T07:28:50.869048Z"}},"outputs":[{"name":"stdout","text":"Validation accuracy: 0.7872340425531915\nsubmission.csv saved.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}