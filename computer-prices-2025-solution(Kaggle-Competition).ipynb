{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ==========================================\n# Computer Prices 2025 â€“ Strong CV Baseline\n# Model: CatBoostRegressor with 5-Fold CV\n# Target: log(price) for training\n# ==========================================\n\nimport os\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\n\nfrom catboost import CatBoostRegressor, Pool\n\n# ------------------------\n# Paths\n# ------------------------\nINPUT_DIR = \"/kaggle/input/computer-prices-2025\"\n\ntrain_path = os.path.join(INPUT_DIR, \"computer_prices_all.csv\")\ntest_path = os.path.join(INPUT_DIR, \"computer_prices_test.csv\")\nsub_path = os.path.join(INPUT_DIR, \"sample_submission.csv\")\n\nprint(\"Input directory contents:\", os.listdir(INPUT_DIR))\n\n# ------------------------\n# Load data\n# ------------------------\ntrain = pd.read_csv(train_path)\ntest = pd.read_csv(test_path)\nsample_sub = pd.read_csv(sub_path)\n\nprint(\"Train shape:\", train.shape)\nprint(\"Test shape:\", test.shape)\nprint(\"Sample submission head:\")\nprint(sample_sub.head())\n\nTARGET_COL = \"price\"\n\n# ------------------------\n# Basic clean-up\n# ------------------------\n# Drop common ID-like columns from features if they exist\nid_cols = [\"id\", \"ID\", \"row_id\", \"Row_ID\", \"index\", \"Unnamed: 0\"]\n\ncols_to_drop = [c for c in id_cols if c in train.columns]\ntrain = train.drop(columns=cols_to_drop, errors=\"ignore\")\ntest = test.drop(columns=cols_to_drop, errors=\"ignore\")\n\n# Make sure target exists\nassert TARGET_COL in train.columns, f\"{TARGET_COL} not found in train!\"\n\n# ------------------------\n# Train/Test feature alignment\n# ------------------------\n# Sometimes train has target + all features, test has only features\n# We'll take intersection of feature columns between train and test\nfeature_cols = [c for c in train.columns if c != TARGET_COL]\n\n# Keep only columns that exist in both\ncommon_features = [c for c in feature_cols if c in test.columns]\ntrain = train[common_features + [TARGET_COL]]\ntest = test[common_features]\n\nprint(\"\\nNumber of features:\", len(common_features))\nprint(\"Features:\", common_features)\n\n# ------------------------\n# Identify categorical features (CatBoost can handle strings)\n# ------------------------\ncat_features = [\n    c for c in common_features\n    if train[c].dtype == \"object\"\n]\nnum_features = [c for c in common_features if c not in cat_features]\n\nprint(\"\\nCategorical features:\", cat_features)\nprint(\"Numeric features:\", num_features)\n\n# ------------------------\n# Optional: simple extra features (very light feature engineering)\n# You can extend this section later.\n# ------------------------\n\ndef add_simple_features(df):\n    # Example combinations if columns exist:\n    # These are safe checks; if a column doesn't exist, we just skip.\n    \n    # total_memory = RAM + VRAM (if present)\n    if \"ram_gb\" in df.columns and \"vram_gb\" in df.columns:\n        df[\"total_memory_gb\"] = df[\"ram_gb\"].fillna(0) + df[\"vram_gb\"].fillna(0)\n    \n    # cpu_power = cores * base_freq\n    if \"cpu_cores\" in df.columns and \"cpu_base_ghz\" in df.columns:\n        df[\"cpu_power_score\"] = df[\"cpu_cores\"].fillna(0) * df[\"cpu_base_ghz\"].fillna(0)\n    \n    # gpu performance proxy\n    if \"gpu_tier\" in df.columns and \"vram_gb\" in df.columns:\n        df[\"gpu_perf_score\"] = df[\"gpu_tier\"].fillna(0) * df[\"vram_gb\"].fillna(0)\n    \n    # storage per ram\n    if \"storage_gb\" in df.columns and \"ram_gb\" in df.columns:\n        df[\"storage_per_ram\"] = df[\"storage_gb\"].fillna(0) / (df[\"ram_gb\"].replace(0, np.nan))\n    \n    return df\n\ntrain = add_simple_features(train)\ntest = add_simple_features(test)\n\n# Update feature lists after adding new features\nfeature_cols = [c for c in train.columns if c != TARGET_COL]\ncommon_features = [c for c in feature_cols if c in test.columns]\ncat_features = [c for c in common_features if train[c].dtype == \"object\"]\nnum_features = [c for c in common_features if c not in cat_features]\n\nprint(\"\\nUpdated number of features:\", len(common_features))\n\n# ------------------------\n# Target transformation: log1p\n# ------------------------\n# Prices are often skewed. log1p can stabilize and improve performance.\ny = train[TARGET_COL].astype(float)\ny_log = np.log1p(y)\n\nX = train[common_features]\nX_test = test[common_features]\n\n# ------------------------\n# K-Fold CV setup\n# ------------------------\nN_FOLDS = 5\nRANDOM_SEED = 42\n\nkf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_SEED)\n\noof_pred = np.zeros(len(train))\ntest_pred = np.zeros(len(test))\nfold_scores = []\n\n# ------------------------\n# CatBoost parameters\n# ------------------------\n# If competition metric is MAE, use:\n#   loss_function=\"MAE\", eval_metric=\"MAE\"\n# and change RMSE code accordingly.\nCAT_PARAMS = dict(\n    loss_function=\"RMSE\",\n    eval_metric=\"RMSE\",\n    depth=8,\n    learning_rate=0.05,\n    l2_leaf_reg=3,\n    random_seed=RANDOM_SEED,\n    iterations=3000,\n    od_type=\"Iter\",\n    od_wait=200,\n    task_type=\"CPU\",   # set to \"GPU\" if GPU is available in your session\n    verbose=200\n)\n\nprint(\"\\nStarting K-Fold training...\")\n\nfor fold, (trn_idx, val_idx) in enumerate(kf.split(X, y_log), 1):\n    print(f\"\\n========== Fold {fold}/{N_FOLDS} ==========\")\n    X_trn, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n    y_trn, y_val = y_log.iloc[trn_idx], y_log.iloc[val_idx]\n    \n    train_pool = Pool(X_trn, y_trn, cat_features=cat_features)\n    valid_pool = Pool(X_val, y_val, cat_features=cat_features)\n    \n    model = CatBoostRegressor(**CAT_PARAMS)\n    model.fit(train_pool, eval_set=valid_pool, use_best_model=True)\n    \n    # OOF predictions in log space\n    val_pred_log = model.predict(X_val)\n    oof_pred[val_idx] = val_pred_log\n    \n    # Transform back to original price space for metric\n    val_pred = np.expm1(val_pred_log)\n    val_true = np.expm1(y_val)\n    \n    rmse = mean_squared_error(val_true, val_pred, squared=False)\n    fold_scores.append(rmse)\n    print(f\"Fold {fold} RMSE: {rmse:.4f}\")\n    \n    # Test predictions (average over folds, still in log space, then transform)\n    test_pred += model.predict(X_test) / N_FOLDS\n\n# ------------------------\n# Overall CV performance\n# ------------------------\n# OOF in original space\noof_pred_price = np.expm1(oof_pred)\nrmse_cv = mean_squared_error(y, oof_pred_price, squared=False)\nprint(\"\\n========== CV Results ==========\")\nprint(\"Fold RMSEs:\", [f\"{s:.4f}\" for s in fold_scores])\nprint(f\"Mean RMSE: {rmse_cv:.4f}, Std: {np.std(fold_scores):.4f}\")\n\n# ------------------------\n# Final test predictions (back-transform)\n# ------------------------\ntest_pred_price = np.expm1(test_pred)\n\n# ------------------------\n# Build submission\n# ------------------------\nsubmission = sample_sub.copy()\n\n# Infer prediction column (non-id)\npred_cols = [c for c in submission.columns if c.lower() not in [\"id\", \"row_id\", \"index\"]]\nif len(pred_cols) != 1:\n    raise ValueError(\n        f\"Could not infer prediction column from sample_submission. \"\n        f\"Found: {pred_cols}. Set it manually.\"\n    )\n\npred_col = pred_cols[0]\nprint(f\"\\nUsing '{pred_col}' as prediction column in submission.\")\n\nsubmission[pred_col] = test_pred_price\n\nsubmission_file = \"submission.csv\"\nsubmission.to_csv(submission_file, index=False)\nprint(f\"Saved submission to {submission_file}\")\nprint(submission.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T09:47:23.470736Z","iopub.execute_input":"2025-12-08T09:47:23.471018Z","iopub.status.idle":"2025-12-08T10:10:26.756178Z","shell.execute_reply.started":"2025-12-08T09:47:23.470996Z","shell.execute_reply":"2025-12-08T10:10:26.754882Z"}},"outputs":[{"name":"stdout","text":"Input directory contents: ['sample_submission.csv', 'computer_prices_all.csv', 'computer_prices_test.csv']\nTrain shape: (100000, 34)\nTest shape: (50000, 33)\nSample submission head:\n       ID    price\n0  100000  1927.99\n1  100001  1927.99\n2  100002  1927.99\n3  100003  1927.99\n4  100004  1927.99\n\nNumber of features: 32\nFeatures: ['device_type', 'brand', 'model', 'release_year', 'os', 'form_factor', 'cpu_brand', 'cpu_model', 'cpu_tier', 'cpu_cores', 'cpu_threads', 'cpu_base_ghz', 'cpu_boost_ghz', 'gpu_brand', 'gpu_model', 'gpu_tier', 'vram_gb', 'ram_gb', 'storage_type', 'storage_gb', 'storage_drive_count', 'display_type', 'display_size_in', 'resolution', 'refresh_hz', 'battery_wh', 'charger_watts', 'psu_watts', 'wifi', 'bluetooth', 'weight_kg', 'warranty_months']\n\nCategorical features: ['device_type', 'brand', 'model', 'os', 'form_factor', 'cpu_brand', 'cpu_model', 'gpu_brand', 'gpu_model', 'storage_type', 'display_type', 'resolution', 'wifi']\nNumeric features: ['release_year', 'cpu_tier', 'cpu_cores', 'cpu_threads', 'cpu_base_ghz', 'cpu_boost_ghz', 'gpu_tier', 'vram_gb', 'ram_gb', 'storage_gb', 'storage_drive_count', 'display_size_in', 'refresh_hz', 'battery_wh', 'charger_watts', 'psu_watts', 'bluetooth', 'weight_kg', 'warranty_months']\n\nUpdated number of features: 36\n\nStarting K-Fold training...\n\n========== Fold 1/5 ==========\n0:\tlearn: 0.2880421\ttest: 0.2877277\tbest: 0.2877277 (0)\ttotal: 218ms\tremaining: 10m 53s\n200:\tlearn: 0.0990192\ttest: 0.0968776\tbest: 0.0968776 (199)\ttotal: 43.9s\tremaining: 10m 11s\n400:\tlearn: 0.0971082\ttest: 0.0960053\tbest: 0.0960050 (399)\ttotal: 1m 26s\tremaining: 9m 19s\n600:\tlearn: 0.0960103\ttest: 0.0958270\tbest: 0.0958269 (598)\ttotal: 2m 9s\tremaining: 8m 38s\n800:\tlearn: 0.0948676\ttest: 0.0956994\tbest: 0.0956994 (800)\ttotal: 3m\tremaining: 8m 14s\n1000:\tlearn: 0.0939139\ttest: 0.0956803\tbest: 0.0956708 (939)\ttotal: 3m 47s\tremaining: 7m 34s\nStopped by overfitting detector  (200 iterations wait)\n\nbestTest = 0.09567078071\nbestIteration = 939\n\nShrink model to first 940 iterations.\nFold 1 RMSE: 195.7107\n\n========== Fold 2/5 ==========\n0:\tlearn: 0.2882111\ttest: 0.2872109\tbest: 0.2872109 (0)\ttotal: 226ms\tremaining: 11m 17s\n200:\tlearn: 0.0984049\ttest: 0.0991760\tbest: 0.0991760 (200)\ttotal: 44s\tremaining: 10m 13s\n400:\tlearn: 0.0962942\ttest: 0.0982139\tbest: 0.0982139 (400)\ttotal: 1m 27s\tremaining: 9m 27s\n600:\tlearn: 0.0951841\ttest: 0.0979773\tbest: 0.0979773 (600)\ttotal: 2m 11s\tremaining: 8m 43s\n800:\tlearn: 0.0942187\ttest: 0.0978867\tbest: 0.0978867 (800)\ttotal: 2m 56s\tremaining: 8m 3s\n1000:\tlearn: 0.0932687\ttest: 0.0978611\tbest: 0.0978597 (999)\ttotal: 3m 41s\tremaining: 7m 21s\n1200:\tlearn: 0.0924305\ttest: 0.0978541\tbest: 0.0978539 (1053)\ttotal: 4m 29s\tremaining: 6m 43s\n1400:\tlearn: 0.0915540\ttest: 0.0978879\tbest: 0.0978532 (1226)\ttotal: 5m 19s\tremaining: 6m 4s\nStopped by overfitting detector  (200 iterations wait)\n\nbestTest = 0.09785315015\nbestIteration = 1226\n\nShrink model to first 1227 iterations.\nFold 2 RMSE: 206.8705\n\n========== Fold 3/5 ==========\n0:\tlearn: 0.2881273\ttest: 0.2873765\tbest: 0.2873765 (0)\ttotal: 230ms\tremaining: 11m 29s\n200:\tlearn: 0.0971852\ttest: 0.1025769\tbest: 0.1025769 (200)\ttotal: 44.8s\tremaining: 10m 23s\n400:\tlearn: 0.0952008\ttest: 0.1018157\tbest: 0.1018153 (395)\ttotal: 1m 27s\tremaining: 9m 27s\n600:\tlearn: 0.0939657\ttest: 0.1016775\tbest: 0.1016739 (598)\ttotal: 2m 11s\tremaining: 8m 43s\n800:\tlearn: 0.0929562\ttest: 0.1016258\tbest: 0.1016212 (793)\ttotal: 2m 57s\tremaining: 8m 6s\n1000:\tlearn: 0.0919992\ttest: 0.1016312\tbest: 0.1016164 (837)\ttotal: 3m 43s\tremaining: 7m 25s\nStopped by overfitting detector  (200 iterations wait)\n\nbestTest = 0.1016164035\nbestIteration = 837\n\nShrink model to first 838 iterations.\nFold 3 RMSE: 253.1027\n\n========== Fold 4/5 ==========\n0:\tlearn: 0.2874687\ttest: 0.2900641\tbest: 0.2900641 (0)\ttotal: 228ms\tremaining: 11m 22s\n200:\tlearn: 0.0981230\ttest: 0.0997335\tbest: 0.0997335 (200)\ttotal: 45.2s\tremaining: 10m 29s\n400:\tlearn: 0.0958893\ttest: 0.0988202\tbest: 0.0988200 (399)\ttotal: 1m 30s\tremaining: 9m 45s\n600:\tlearn: 0.0946278\ttest: 0.0986451\tbest: 0.0986445 (599)\ttotal: 2m 15s\tremaining: 8m 59s\n800:\tlearn: 0.0935174\ttest: 0.0985730\tbest: 0.0985730 (800)\ttotal: 3m\tremaining: 8m 16s\n1000:\tlearn: 0.0926903\ttest: 0.0985909\tbest: 0.0985730 (800)\ttotal: 3m 45s\tremaining: 7m 29s\nStopped by overfitting detector  (200 iterations wait)\n\nbestTest = 0.0985729553\nbestIteration = 800\n\nShrink model to first 801 iterations.\nFold 4 RMSE: 214.0688\n\n========== Fold 5/5 ==========\n0:\tlearn: 0.2880768\ttest: 0.2875525\tbest: 0.2875525 (0)\ttotal: 228ms\tremaining: 11m 23s\n200:\tlearn: 0.0987371\ttest: 0.0962337\tbest: 0.0962337 (200)\ttotal: 45s\tremaining: 10m 26s\n400:\tlearn: 0.0965941\ttest: 0.0952532\tbest: 0.0952532 (400)\ttotal: 1m 29s\tremaining: 9m 42s\n600:\tlearn: 0.0954251\ttest: 0.0950912\tbest: 0.0950896 (598)\ttotal: 2m 15s\tremaining: 9m 2s\n800:\tlearn: 0.0943759\ttest: 0.0950099\tbest: 0.0950099 (800)\ttotal: 3m 4s\tremaining: 8m 25s\n1000:\tlearn: 0.0934377\ttest: 0.0949884\tbest: 0.0949834 (952)\ttotal: 3m 50s\tremaining: 7m 41s\n1200:\tlearn: 0.0924746\ttest: 0.0949759\tbest: 0.0949703 (1188)\ttotal: 4m 37s\tremaining: 6m 56s\nStopped by overfitting detector  (200 iterations wait)\n\nbestTest = 0.09497034891\nbestIteration = 1188\n\nShrink model to first 1189 iterations.\nFold 5 RMSE: 203.2975\n\n========== CV Results ==========\nFold RMSEs: ['195.7107', '206.8705', '253.1027', '214.0688', '203.2975']\nMean RMSE: 215.5525, Std: 20.1347\n\nUsing 'price' as prediction column in submission.\nSaved submission to submission.csv\n       ID        price\n0  100000  2908.201923\n1  100001  2454.600520\n2  100002  1242.135335\n3  100003  1466.217551\n4  100004  3254.772244\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"submission[pred_col] = test_pred_price\n\nsubmission_file = \"submission.csv\"\nsubmission.to_csv(submission_file, index=False)\nprint(f\"Saved submission to {submission_file}\")\nprint(submission.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T10:22:45.840847Z","iopub.execute_input":"2025-12-08T10:22:45.841663Z","iopub.status.idle":"2025-12-08T10:22:45.959470Z","shell.execute_reply.started":"2025-12-08T10:22:45.841628Z","shell.execute_reply":"2025-12-08T10:22:45.958133Z"}},"outputs":[{"name":"stdout","text":"Saved submission to submission.csv\n       ID        price\n0  100000  2908.201923\n1  100001  2454.600520\n2  100002  1242.135335\n3  100003  1466.217551\n4  100004  3254.772244\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}